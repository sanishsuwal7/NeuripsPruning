{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "789a2557-5dbf-43a2-a5d9-a45769a813f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import torch.optim as optim\n",
    "from cleverhans.torch.attacks.projected_gradient_descent import (projected_gradient_descent)\n",
    "\n",
    "import quantus\n",
    "import captum\n",
    "from captum.attr import Saliency, IntegratedGradients, NoiseTunnel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import gc\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from resnet_18 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd58378c-41af-44f0-9c36-50bd3d0aa1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb4934b8-9d2b-46d1-9bc3-a2a4a276957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e91f6e9b-7045-40d4-b041-0c8ad2540529",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils.ipynb\n",
    "%run metrics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70895d69-1cee-4ca4-9eef-19317edbece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_path = '../datasets/imagenette2/train'\n",
    "val_path = '../datasets/imagenette2/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0b6f4c0-9af8-4e2d-a8e0-264ffef0cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(datasets.ImageFolder(train_path, transform = transforms.Compose([\n",
    "                                                                    transforms.RandomResizedCrop(224),\n",
    "                                                                    transforms.RandomHorizontalFlip(),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                        std=[0.229, 0.224, 0.225])\n",
    "                                                            ])), batch_size = batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "test_dataloader = DataLoader(datasets.ImageFolder(val_path,\n",
    "                                                               transform=transforms.Compose([\n",
    "                                                                   transforms.ToTensor(),\n",
    "                                                                   transforms.Resize([224, 224]),\n",
    "                                                                   transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                        std=[0.229, 0.224, 0.225])\n",
    "                                                               ])),batch_size=batch_size, shuffle=True,num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9742a475-96d0-41e8-a6f6-118d2ecdd438",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['tench', 'springer', 'casette_player', 'chain_saw','church', 'French_horn', 'garbage_truck', 'gas_pump', 'golf_ball', 'parachute']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5b653e8-c20c-46a5-b0ae-1c46c5e80305",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction=\"mean\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e61e5866-0c13-47ce-8f2d-e508484d2cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explainer_wrapper(**kwargs):\n",
    "    \"\"\"\n",
    "    A wrapper function to call the appropriate explanation method.\n",
    "\n",
    "    \"\"\"\n",
    "    if kwargs[\"method\"] == \"SmoothGrad\":\n",
    "        return smoothgrad_explainer(**kwargs)\n",
    "    else:\n",
    "        return ValueError(\"Explanation function doesnt exist\")\n",
    "\n",
    "\n",
    "\n",
    "def smoothgrad_explainer(model, inputs, targets, abs=True, normalise=True, stdevs=0.15, nt_samples=10, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate explanations for a model's predictions using the SmoothGrad method.\n",
    "\n",
    "    Args:\n",
    "        model: The model to explain.\n",
    "        inputs : Input samples.\n",
    "        targets: Target labels corresponding to the inputs.\n",
    "        abs : Whether to use the absolute value of gradients.\n",
    "        normalise: Whether to normalize the explanation\n",
    "        stdevs: Standard deviation of the noise added to inputs\n",
    "        nt_samples: Number of noisy samples to generate for SmoothGrad.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Explanation maps for the input samples.\n",
    "    \"\"\"\n",
    "    std = kwargs.get(\"std\", 0.15)  # Standard deviation for input noise\n",
    "    n = kwargs.get(\"n\", 10)  # Number of noisy samples\n",
    "    clip = kwargs.get(\"clip\", False)\n",
    "\n",
    "    model.to(kwargs.get(\"device\", None))\n",
    "    model.eval()\n",
    "\n",
    "    if not isinstance(inputs, torch.Tensor):\n",
    "        inputs = (\n",
    "            torch.Tensor(inputs).reshape(-1,kwargs.get(\"nr_channels\", 3),kwargs.get(\"img_size\", 224),kwargs.get(\"img_size\", 224),).to(kwargs.get(\"device\", None))\n",
    "        )\n",
    "    \n",
    "    if not isinstance(targets, torch.Tensor):\n",
    "        targets = torch.as_tensor(targets).long().to(kwargs.get(\"device\", None))\n",
    "\n",
    "    assert (len(np.shape(inputs)) == 4), \"Inputs should be shaped (nr_samples, nr_channels, img_size, img_size\"\n",
    "\n",
    "    if inputs.shape[0] > 1:\n",
    "        explanation = torch.zeros(\n",
    "            (\n",
    "                n,\n",
    "                inputs.shape[0],\n",
    "                kwargs.get(\"img_size\", 224),\n",
    "                kwargs.get(\"img_size\", 224),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        explanation = torch.zeros(\n",
    "            (n, kwargs.get(\"img_size\", 224), kwargs.get(\"img_size\", 224))\n",
    "        )\n",
    "    saliency = Saliency(model)\n",
    "    \n",
    "    explanation = (\n",
    "        NoiseTunnel(saliency)\n",
    "        .attribute(inputs=inputs, target=targets, nt_type=\"smoothgrad\", stdevs = stdevs, nt_samples= 10)\n",
    "        .sum(axis=1)\n",
    "        .reshape(-1, kwargs.get(\"img_size\", 224), kwargs.get(\"img_size\", 224))\n",
    "        .cpu()\n",
    "        .data\n",
    "    )\n",
    "\n",
    "    # explanation = explanation.mean(axis=0)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    explanation = explanation.numpy()\n",
    "    # Normalization (if required)\n",
    "    if normalise:\n",
    "        explanation = quantus.normalise_func.normalise_by_negative(explanation)\n",
    "\n",
    "    # Convert the result to NumPy if it is still a PyTorch tensor\n",
    "    if isinstance(explanation, torch.Tensor):\n",
    "        if explanation.requires_grad:\n",
    "            return explanation.cpu().detach().numpy()\n",
    "        return explanation.cpu().numpy()\n",
    "\n",
    "    return explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "689c64b4-1a5f-4189-bbed-d86f7e5c2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "xai_method=[\"SmoothGrad\"]\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de4a931-d0b0-462f-9c3f-6448639255f3",
   "metadata": {},
   "source": [
    "## Vanilla Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b06c642-5d45-4cef-8182-4bc401b98d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.15%\n",
      "The road score is:  {1: np.float64(0.9854187562209861), 11: np.float64(0.9302623147929386), 21: np.float64(0.8855254694918366), 31: np.float64(0.8275752431472999), 41: np.float64(0.7686531744591676), 51: np.float64(0.7003263311118203), 61: np.float64(0.6167151750011796), 71: np.float64(0.5189097090335428), 81: np.float64(0.41946263606951006), 91: np.float64(0.30242259808422944)}\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/0_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.eval()\n",
    "accuracy = test(model, test_dataloader, criterion)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "result_normal = filter_and_compute_road(model, test_dataloader, \"Saliency\", device, resnet = True)\n",
    "print(\"The road score is: \", result_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e484718-7ebd-45a7-8466-bcde0291bf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.10%\n",
      "The road score is:  {1: np.float64(0.9837310536786187), 11: np.float64(0.929972869715964), 21: np.float64(0.866104104853331), 31: np.float64(0.8072800443816678), 41: np.float64(0.7171702227608943), 51: np.float64(0.6231640628883724), 61: np.float64(0.5228790319156869), 71: np.float64(0.4260239943928879), 81: np.float64(0.3296042879105286), 91: np.float64(0.2543334457371799)}\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/1_5_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "accuracy = test(model, test_dataloader, criterion)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "result_normal = filter_and_compute_road(model, test_dataloader, \"Saliency\", device, resnet = True)\n",
    "print(\"The road score is: \", result_normal)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b4f2142-8ddc-455c-ac23-62c294672a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 83.13%\n",
      "The road score is:  {1: np.float64(0.9799208963778208), 11: np.float64(0.9136983714162727), 21: np.float64(0.8637160553598301), 31: np.float64(0.8006494027445334), 41: np.float64(0.7237594767473243), 51: np.float64(0.6276571377706955), 61: np.float64(0.5362060711547837), 71: np.float64(0.43228985890760535), 81: np.float64(0.3291858131864658), 91: np.float64(0.25164405727791406)}\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/1_10_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "accuracy = test(model, test_dataloader, criterion)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "result_normal = filter_and_compute_road(model, test_dataloader, \"Saliency\", device, resnet = True)\n",
    "print(\"The road score is: \", result_normal)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8da56644-948a-4c39-883c-79516ed66ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.18%\n",
      "The road score is:  {1: np.float64(0.9800060568550581), 11: np.float64(0.9197179038239468), 21: np.float64(0.8670742404008076), 31: np.float64(0.8091293294324844), 41: np.float64(0.7264244267648965), 51: np.float64(0.6474040927489494), 61: np.float64(0.5544084061680202), 71: np.float64(0.4606913360362517), 81: np.float64(0.3678827795588879), 91: np.float64(0.2800112830488548)}\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/1_15_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "accuracy = test(model, test_dataloader, criterion)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "result_normal = filter_and_compute_road(model, test_dataloader, \"Saliency\", device, resnet = True)\n",
    "print(\"The road score is: \", result_normal)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f97fb389-179c-46c6-8a86-b2d3e551459e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.31%\n",
      "The road score is:  {1: np.float64(0.9815317446919453), 11: np.float64(0.916264309570018), 21: np.float64(0.8550035656800294), 31: np.float64(0.78959464373224), 41: np.float64(0.7143713719788255), 51: np.float64(0.6170017447664645), 61: np.float64(0.535769578517576), 71: np.float64(0.440189077713297), 81: np.float64(0.34097142622121834), 91: np.float64(0.2647278476711539)}\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/1_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.eval()\n",
    "accuracy = test(model, test_dataloader, criterion)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "result_normal = filter_and_compute_road(model, test_dataloader, \"Saliency\", device, resnet = True)\n",
    "print(\"The road score is: \", result_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c22ed990-84f3-4d46-9575-76df04d97e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 85.55%\n",
      "The road score is:  {1: np.float64(0.9820257658315142), 11: np.float64(0.9274665111306769), 21: np.float64(0.8728924914795306), 31: np.float64(0.8038201046585481), 41: np.float64(0.7230428491972497), 51: np.float64(0.6394828207378183), 61: np.float64(0.5341273658014597), 71: np.float64(0.42564235011338775), 81: np.float64(0.33250923822599016), 91: np.float64(0.24350088953506518)}\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/2_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "accuracy = test(model, test_dataloader, criterion)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "result_normal = filter_and_compute_road(model, test_dataloader, \"Saliency\", device, resnet = True)\n",
    "print(\"The road score is: \", result_normal)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b891c48-f2c1-489b-a15d-c10840417e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 85.63%\n",
      "The road score is:  {1: np.float64(0.9815523567285375), 11: np.float64(0.9356981658686606), 21: np.float64(0.8902092786831333), 31: np.float64(0.8415169642088424), 41: np.float64(0.7749564670168705), 51: np.float64(0.6978569255157439), 61: np.float64(0.60888594593442), 71: np.float64(0.5116983727967653), 81: np.float64(0.4039617397451793), 91: np.float64(0.3028486530926366)}\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/6_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "accuracy = test(model, test_dataloader, criterion)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "result_normal = filter_and_compute_road(model, test_dataloader, \"Saliency\", device, resnet = True)\n",
    "print(\"The road score is: \", result_normal)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7679a22-4c8d-4907-bd5d-10d4c9723989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.43%\n",
      "The road score is:  {1: np.float64(0.9835630670525478), 11: np.float64(0.9342213103810895), 21: np.float64(0.8821054857545466), 31: np.float64(0.8255040473880926), 41: np.float64(0.7546564625140637), 51: np.float64(0.6619870188715149), 61: np.float64(0.5630498173438654), 71: np.float64(0.46577110960962625), 81: np.float64(0.3588333885456528), 91: np.float64(0.25681642034993374)}\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/12_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "accuracy = test(model, test_dataloader, criterion)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "result_normal = filter_and_compute_road(model, test_dataloader, \"Saliency\", device, resnet = True)\n",
    "print(\"The road score is: \", result_normal)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "081e3664-e6e7-436f-aff5-c2f7aa424d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 82.70%\n",
      "The road score is:  {1: np.float64(0.9847261184524104), 11: np.float64(0.9267461343208111), 21: np.float64(0.8685318018749423), 31: np.float64(0.807615101667683), 41: np.float64(0.7248794158224089), 51: np.float64(0.6496159754595252), 61: np.float64(0.5688044644775477), 71: np.float64(0.475189554305934), 81: np.float64(0.3775650117210429), 91: np.float64(0.28272291065287086)}\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/18_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "accuracy = test(model, test_dataloader, criterion)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "result_normal = filter_and_compute_road(model, test_dataloader, \"Saliency\", device, resnet = True)\n",
    "print(\"The road score is: \", result_normal)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71153524-114b-4145-96e9-faf0ff632e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 83.46%\n",
      "The road score is:  {1: np.float64(0.9860395021377726), 11: np.float64(0.9380568182055771), 21: np.float64(0.8859509869049661), 31: np.float64(0.8254678674765173), 41: np.float64(0.7475342621319393), 51: np.float64(0.651121103479216), 61: np.float64(0.5477292968705794), 71: np.float64(0.446885111033178), 81: np.float64(0.34203169419053664), 91: np.float64(0.24484063846912646)}\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/29_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "accuracy = test(model, test_dataloader, criterion)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "result_normal = filter_and_compute_road(model, test_dataloader, \"Saliency\", device, resnet = True)\n",
    "print(\"The road score is: \", result_normal)\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7648483-db6a-4abf-894e-4f85cd5d421e",
   "metadata": {},
   "source": [
    "## Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e470b08e-7dee-4a5c-aee7-4dbd292c2de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ae4ad-78f0-4e63-a585-ee071eea194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/0_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "result_normal = filter_and_compute_road(model, test_dataloader, \"IntegratedGradients\", device, resnet = True)\n",
    "print(\"The road score is: \", result_normal)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb955b-65d6-42c3-8d25-aa3e6d0009fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/1_5_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "\n",
    "result_prune_5 = filter_and_compute_road(model, test_dataloader, \"IntegratedGradients\", device, resnet = True)\n",
    "print(\"The road score is: \", result_prune_5)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed0724-f712-41d1-badc-f0c124e00d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/1_10_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "\n",
    "result_prune_10 = filter_and_compute_road(model, test_dataloader, \"IntegratedGradients\", device, resnet = True)\n",
    "print(\"The road score is: \", result_prune_10)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4402d023-4894-409f-ae08-2aa2e0cb4d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/1_15_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "\n",
    "result_prune_15 = filter_and_compute_road(model, test_dataloader, \"IntegratedGradients\", device, resnet = True)\n",
    "print(\"The road score is: \", result_prune_15)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b701c1bb-d872-4f75-b94a-611d776ec02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/1_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "result_prune_20 = filter_and_compute_road(model, test_dataloader, \"IntegratedGradients\", device, resnet = True)\n",
    "print(\"The road score is: \", result_prune_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37deaea-0eac-48de-b304-0050173d6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/2_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "\n",
    "result_prune_30 = filter_and_compute_road(model, test_dataloader, \"IntegratedGradients\", device, resnet = True)\n",
    "print(\"The road score is: \", result_prune_30)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0e8d5-5f06-4119-a9ab-b0aa300e9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/6_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "\n",
    "result_prune_40 = filter_and_compute_road(model, test_dataloader, \"IntegratedGradients\", device, resnet = True)\n",
    "print(\"The road score is: \", result_prune_40)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039eefc-3b0d-4ecf-aa39-893508b9b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/12_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "\n",
    "result_prune_50 = filter_and_compute_road(model, test_dataloader, \"IntegratedGradients\", device, resnet = True)\n",
    "print(\"The road score is: \", result_prune_50)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae663e-d581-4a43-a25a-358ac3a49c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/18_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "\n",
    "result_prune_60 = filter_and_compute_road(model, test_dataloader, \"IntegratedGradients\", device, resnet = True)\n",
    "print(\"The road score is: \", result_prune_60)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9b852-e7e5-4b79-9df0-55e191585680",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"saves/resnet/imagenette/29_model_lt.pth.tar\"\n",
    "model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "\n",
    "result_prune_70 = filter_and_compute_road(model, test_dataloader, \"IntegratedGradients\", device, resnet = True)\n",
    "print(\"The road score is: \", result_prune_70)\n",
    "del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
